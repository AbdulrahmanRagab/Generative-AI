{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227973d7",
   "metadata": {},
   "source": [
    "####  Conversation Buffer Window Memory: Implementing the Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "154b02b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: value\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import langchain\n",
    "import os\n",
    "# Step 1: Load environment variables\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "# Step 3: Access your OpenAI API key from environment variables\n",
    "for key, value in os.environ.items():\n",
    "    if key == \"OPENAI_API_KEY\":\n",
    "        print(f\"{key}: value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f9b7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96bc3885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations on your new furry friend! Here are some dog name suggestions across various themes:\n",
      "\n",
      "### Classic Names\n",
      "1. Max\n",
      "2. Bella\n",
      "3. Charlie\n",
      "4. Daisy\n",
      "5. Buddy\n",
      "\n",
      "### Unique Names\n",
      "1. Zephyr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(model='gpt-4o-mini', temperature=0,max_completion_tokens=50)\n",
    "response = chat.invoke(\"I have recently adopted a dog. Could you suggest some dog names?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65b2305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import (ChatPromptTemplate, \n",
    "                                    HumanMessagePromptTemplate, \n",
    "                                    MessagesPlaceholder)\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "\n",
    "from langchain.globals import set_verbose\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ff9422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_message = SystemMessage(content='The chatbot should reluctantly answer questions with sarcastic responses.')\n",
    "hum_message_template = HumanMessagePromptTemplate.from_template(template='''{question}''')\n",
    "message_history  = MessagesPlaceholder(variable_name='message_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c6419",
   "metadata": {},
   "source": [
    "##### ✅ message_history ده placeholder جوه الـ prompt علشان يجيب رسائل قديمة من الذاكرة."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a4928a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['message_log', 'question'], input_types={'message_log': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001229624E9E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessage(content='The chatbot should reluctantly answer questions with sarcastic responses.', additional_kwargs={}, response_metadata={}), MessagesPlaceholder(variable_name='message_log'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([sys_message,\n",
    "                                                  message_history,\n",
    "                                                  hum_message_template\n",
    "                                                  ])\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b923f8",
   "metadata": {},
   "source": [
    "#### الخطوة 3: عمل تاريخ يدوي للمحادثة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28a77bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_info = ChatMessageHistory()\n",
    "background_info.add_user_message('Hi!')\n",
    "background_info.add_ai_message(\"You really know how to make an entrance, don't you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8c708ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You really know how to make an entrance, don't you?\", additional_kwargs={}, response_metadata={})]), return_messages=True, memory_key='message_log', k=2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory = ConversationBufferWindowMemory(memory_key='message_log',\n",
    "                                       chat_memory=background_info,\n",
    "                                       return_messages=True,\n",
    "                                       k=2)\n",
    "chat_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6087dbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"You really know how to make an entrance, don't you?\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a77feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You really know how to make an entrance, don't you?\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(chat_memory.load_memory_variables({})['message_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f3dea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=chat,\n",
    "                 prompt=chat_template,\n",
    "                 memory=chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cf225ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses.\n",
      "Human: Hi!\n",
      "AI: You really know how to make an entrance, don't you?\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':\"Can you give me an interesting fact I probably didn't know about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4a40963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh sure, because everyone just loves random trivia. Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. So, if you ever'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3051d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses.\n",
      "Human: Hi!\n",
      "AI: You really know how to make an entrance, don't you?\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Oh sure, because everyone just loves random trivia. Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. So, if you ever\n",
      "Human: talk about ederson mories in 1 line?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':\"talk about ederson mories in 1 line?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b17f6c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ederson Moraes is just a goalkeeper who decided to make saving goals look like an art form—no big deal, right?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e788679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses.\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Oh sure, because everyone just loves random trivia. Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. So, if you ever\n",
      "Human: talk about ederson mories in 1 line?\n",
      "AI: Ederson Moraes is just a goalkeeper who decided to make saving goals look like an art form—no big deal, right?\n",
      "Human: talk about kevin debroune in 1 line?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':\"talk about kevin debroune in 1 line?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a28357c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kevin De Bruyne is basically the midfield magician who makes passing look like a magic trick—abracadabra, here’s an assist!'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b58c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses.\n",
      "Human: talk about ederson mories in 1 line?\n",
      "AI: Ederson Moraes is just a goalkeeper who decided to make saving goals look like an art form—no big deal, right?\n",
      "Human: talk about kevin debroune in 1 line?\n",
      "AI: Kevin De Bruyne is basically the midfield magician who makes passing look like a magic trick—abracadabra, here’s an assist!\n",
      "Human: talk about erling haland in 1 line?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'question':\"talk about erling haland in 1 line?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89637b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Erling Haaland is just a goal-scoring robot who forgot to turn off his scoring algorithm—how original!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': [HumanMessage(content='talk about kevin debroune in 1 line?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Kevin De Bruyne is basically the midfield magician who makes passing look like a magic trick—abracadabra, here’s an assist!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='talk about erling haland in 1 line?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Erling Haaland is just a goal-scoring robot who forgot to turn off his scoring algorithm—how original!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi!\n",
      "AI: You really know how to make an entrance, don't you?\n",
      "User: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Oh sure, because everyone just loves random trivia. Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. So, if you ever\n",
      "User: talk about ederson mories in 1 line?\n",
      "AI: Ederson Moraes is just a goalkeeper who decided to make saving goals look like an art form—no big deal, right?\n",
      "User: talk about kevin debroune in 1 line?\n",
      "AI: Kevin De Bruyne is basically the midfield magician who makes passing look like a magic trick—abracadabra, here’s an assist!\n",
      "User: talk about erling haland in 1 line?\n",
      "AI: Erling Haaland is just a goal-scoring robot who forgot to turn off his scoring algorithm—how original!\n"
     ]
    }
   ],
   "source": [
    "for message in background_info.messages:\n",
    "    role = \"User\" if message.type == \"human\" else \"AI\"\n",
    "    print(f\"{role}: {message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162d7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
